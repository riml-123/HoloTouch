{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9ab29e",
   "metadata": {},
   "source": [
    "### 데이터 균형 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c74644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN 데이터 분포 확인 중...\n",
      "--------------------------------------------------\n",
      "Label Name                     | Video Count\n",
      "--------------------------------------------------\n",
      "No gesture                     |  1844\n",
      "Doing other things             |  4374\n",
      "Zooming In With Two Fingers    |  1801\n",
      "Zooming Out With Two Fingers   |  1847\n",
      "Zooming In With Full Hand      |  1799\n",
      "Zooming Out With Full Hand     |  1832\n",
      "Thumb Up                       |  1841\n",
      "Thumb Down                     |  1810\n",
      "--------------------------------------------------\n",
      "Total                          | 17148\n",
      "--------------------------------------------------\n",
      "\n",
      "VAL 데이터 분포 확인 중...\n",
      "--------------------------------------------------\n",
      "Label Name                     | Video Count\n",
      "--------------------------------------------------\n",
      "No gesture                     |   256\n",
      "Doing other things             |   713\n",
      "Zooming In With Two Fingers    |   257\n",
      "Zooming Out With Two Fingers   |   261\n",
      "Zooming In With Full Hand      |   262\n",
      "Zooming Out With Full Hand     |   260\n",
      "Thumb Up                       |   238\n",
      "Thumb Down                     |   250\n",
      "--------------------------------------------------\n",
      "Total                          |  2497\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DATA_ROOT = r\"D:\\학교\\3-2\\파이썬기반 딥러닝\\3-2_jester_recognation\\jester_mediapipe_csv\"\n",
    "\n",
    "TARGET_LABELS = [\n",
    "    \"No gesture\",\n",
    "    \"Doing other things\",\n",
    "    \"Zooming In With Two Fingers\",\n",
    "    \"Zooming Out With Two Fingers\",\n",
    "    \"Zooming In With Full Hand\",\n",
    "    \"Zooming Out With Full Hand\",\n",
    "    \"Thumb Up\",    \n",
    "    \"Thumb Down\" \n",
    "]\n",
    "def print_distribution(split_name):\n",
    "    csv_path = os.path.join(DATA_ROOT, f\"{split_name}_data.csv\")\n",
    "    \n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"{split_name} 파일을 찾을 수 없습니다: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{split_name.upper()} 데이터 분포 확인 중...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, usecols=['video_id', 'label_name']) # 전체 데이터를 다 읽으면 느리므로, 필요한 컬럼만 로드\n",
    "        \n",
    "        counts = df.groupby('label_name')['video_id'].nunique() # 라벨별 고유한 video_id 개수 세기 (nunique)\n",
    "        \n",
    "        total_videos = 0\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Label Name':<30} | {'Video Count'}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for label in TARGET_LABELS:\n",
    "            # 해당 라벨이 데이터에 없으면 0으로 처리\n",
    "            count = counts.get(label, 0)\n",
    "            print(f\"{label:<30} | {count:5d}\")\n",
    "            total_videos += count\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(f\"{'Total':<30} | {total_videos:5d}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"파일 읽기 오류: {e}\")\n",
    "\n",
    "print_distribution('train')\n",
    "print_distribution('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc270b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Starting Training with Train/Val Split...\n",
      "Loading D:\\학교\\3-2\\파이썬기반 딥러닝\\3-2_jester_recognation\\jester_mediapipe_csv\\train_data.csv...\n",
      "Data Split: Train 13718 / Val 3430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 | Train Loss: 1.1957 Acc: 0.5571 | Val Loss: 1.0684 Acc: 0.6382\n",
      "Best Model Saved! (Loss: 1.0684)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2 | Train Loss: 0.7542 Acc: 0.7717 | Val Loss: 0.7904 Acc: 0.7554\n",
      "Best Model Saved! (Loss: 0.7904)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3 | Train Loss: 0.6308 Acc: 0.8169 | Val Loss: 0.6893 Acc: 0.7895\n",
      "Best Model Saved! (Loss: 0.6893)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4 | Train Loss: 0.6176 Acc: 0.8177 | Val Loss: 0.6759 Acc: 0.7977\n",
      "Best Model Saved! (Loss: 0.6759)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 5 | Train Loss: 0.5815 Acc: 0.8283 | Val Loss: 0.6144 Acc: 0.8146\n",
      "Best Model Saved! (Loss: 0.6144)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 6 | Train Loss: 0.5570 Acc: 0.8343 | Val Loss: 0.6313 Acc: 0.8090\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 7 | Train Loss: 0.5659 Acc: 0.8303 | Val Loss: 0.6630 Acc: 0.7977\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 8 | Train Loss: 0.5582 Acc: 0.8336 | Val Loss: 0.6317 Acc: 0.8076\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 9 | Train Loss: 0.5213 Acc: 0.8468 | Val Loss: 0.5988 Acc: 0.8166\n",
      "Best Model Saved! (Loss: 0.5988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 10 | Train Loss: 0.5200 Acc: 0.8462 | Val Loss: 0.5910 Acc: 0.8233\n",
      "Best Model Saved! (Loss: 0.5910)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 11 | Train Loss: 0.5173 Acc: 0.8451 | Val Loss: 0.5659 Acc: 0.8259\n",
      "Best Model Saved! (Loss: 0.5659)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 12 | Train Loss: 0.4967 Acc: 0.8501 | Val Loss: 0.5836 Acc: 0.8187\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 13 | Train Loss: 0.5099 Acc: 0.8444 | Val Loss: 0.5835 Acc: 0.8265\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 14 | Train Loss: 0.4930 Acc: 0.8528 | Val Loss: 0.5616 Acc: 0.8251\n",
      "Best Model Saved! (Loss: 0.5616)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 15 | Train Loss: 0.4932 Acc: 0.8521 | Val Loss: 0.5469 Acc: 0.8297\n",
      "Best Model Saved! (Loss: 0.5469)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 16 | Train Loss: 0.4854 Acc: 0.8539 | Val Loss: 0.5631 Acc: 0.8233\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 17 | Train Loss: 0.4645 Acc: 0.8600 | Val Loss: 0.5700 Acc: 0.8248\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 18 | Train Loss: 0.4682 Acc: 0.8600 | Val Loss: 0.5398 Acc: 0.8309\n",
      "Best Model Saved! (Loss: 0.5398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 19 | Train Loss: 0.4552 Acc: 0.8623 | Val Loss: 0.5380 Acc: 0.8341\n",
      "Best Model Saved! (Loss: 0.5380)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 20 | Train Loss: 0.4494 Acc: 0.8650 | Val Loss: 0.5335 Acc: 0.8341\n",
      "Best Model Saved! (Loss: 0.5335)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 21 | Train Loss: 0.4598 Acc: 0.8611 | Val Loss: 0.5841 Acc: 0.8242\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 22 | Train Loss: 0.4560 Acc: 0.8624 | Val Loss: 0.5537 Acc: 0.8280\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 23 | Train Loss: 0.4543 Acc: 0.8643 | Val Loss: 0.5415 Acc: 0.8321\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 24 | Train Loss: 0.4390 Acc: 0.8638 | Val Loss: 0.5418 Acc: 0.8297\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 25 | Train Loss: 0.4529 Acc: 0.8631 | Val Loss: 0.5327 Acc: 0.8350\n",
      "Best Model Saved! (Loss: 0.5327)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 26 | Train Loss: 0.4445 Acc: 0.8665 | Val Loss: 0.5523 Acc: 0.8271\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 27 | Train Loss: 0.4365 Acc: 0.8668 | Val Loss: 0.5352 Acc: 0.8289\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 28 | Train Loss: 0.4359 Acc: 0.8662 | Val Loss: 0.5251 Acc: 0.8347\n",
      "Best Model Saved! (Loss: 0.5251)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 29 | Train Loss: 0.4250 Acc: 0.8693 | Val Loss: 0.5459 Acc: 0.8300\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 30 | Train Loss: 0.4321 Acc: 0.8668 | Val Loss: 0.5449 Acc: 0.8292\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 31 | Train Loss: 0.4246 Acc: 0.8681 | Val Loss: 0.5467 Acc: 0.8329\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 32 | Train Loss: 0.4115 Acc: 0.8720 | Val Loss: 0.5253 Acc: 0.8397\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 33 | Train Loss: 0.4253 Acc: 0.8711 | Val Loss: 0.5365 Acc: 0.8327\n",
      "EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 34 | Train Loss: 0.4089 Acc: 0.8736 | Val Loss: 0.5343 Acc: 0.8329\n",
      "EarlyStopping counter: 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 35 | Train Loss: 0.3942 Acc: 0.8799 | Val Loss: 0.5406 Acc: 0.8329\n",
      "EarlyStopping counter: 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 36 | Train Loss: 0.4081 Acc: 0.8726 | Val Loss: 0.5366 Acc: 0.8327\n",
      "EarlyStopping counter: 8 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 37 | Train Loss: 0.3817 Acc: 0.8822 | Val Loss: 0.5262 Acc: 0.8382\n",
      "EarlyStopping counter: 9 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 38 | Train Loss: 0.3750 Acc: 0.8851 | Val Loss: 0.5310 Acc: 0.8321\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping at epoch 38\n",
      "\n",
      "========================================\n",
      "Training Finished!\n",
      "Best Val Accuracy: 0.8397\n",
      "Model saved to: best_split_model.pth\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from model import SE_TCN\n",
    "\n",
    "DATA_ROOT = r\"D:\\학교\\3-2\\파이썬기반 딥러닝\\3-2_jester_recognation\\jester_mediapipe_csv\"\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_ROOT, \"train_data.csv\")\n",
    "SAVE_MODEL_PATH = \"best_split_model.pth\"\n",
    "TARGET_LABELS = [\n",
    "    \"No gesture\",\n",
    "    \"Doing other things\",\n",
    "    \"Zooming In With Two Fingers\",\n",
    "    \"Zooming Out With Two Fingers\",\n",
    "    \"Zooming In With Full Hand\",\n",
    "    \"Zooming Out With Full Hand\",\n",
    "    \"Thumb Up\",\n",
    "    \"Thumb Down\"\n",
    "]\n",
    "LABEL_MAP = {label: i for i, label in enumerate(TARGET_LABELS)}\n",
    "NUM_CLASSES = len(TARGET_LABELS)\n",
    "VAL_SIZE = 0.2       \n",
    "INPUT_CHANNELS = 126  # (21*3 + 21*3)\n",
    "MAX_SEQ_LEN = 40\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class JesterRawDataset(Dataset): # 데이터셋 정의\n",
    "    def __init__(self, csv_path):\n",
    "        print(f\"Loading {csv_path}...\")\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df = self.df[self.df['label_name'].isin(TARGET_LABELS)]\n",
    "        self.grouped = self.df.groupby('video_id')\n",
    "        self.video_ids = list(self.grouped.groups.keys())\n",
    "        self.feat_cols = []\n",
    "        for i in range(21):\n",
    "            self.feat_cols.extend([f'joint_{i}_x', f'joint_{i}_y', f'joint_{i}_z'])\n",
    "        self.labels = []\n",
    "        for vid in self.video_ids:\n",
    "            label_str = self.grouped.get_group(vid).iloc[0]['label_name']\n",
    "            self.labels.append(LABEL_MAP[label_str])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_ids)\n",
    "\n",
    "    def get_labels_by_indices(self, indices):\n",
    "        return [self.labels[i] for i in indices]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vid_id = self.video_ids[idx]\n",
    "        group = self.grouped.get_group(vid_id)\n",
    "        label_name = group.iloc[0]['label_name']\n",
    "        label = LABEL_MAP[label_name]\n",
    "        features = group[self.feat_cols].replace(0, np.nan).interpolate().fillna(0).values.astype(np.float32)\n",
    "        return features, label\n",
    "\n",
    "\n",
    "# Transforms(증강 기법 적용)\n",
    "class RandomHorizontalFlip:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if random.random() < self.p:\n",
    "            x = x.copy()\n",
    "            x[:, 0::3] *= -1\n",
    "        return x\n",
    "\n",
    "class NormalizeSkeleton: # 정규화\n",
    "    def __call__(self, x):\n",
    "        T = x.shape[0]\n",
    "        skeleton = x.reshape(T, 21, 3)\n",
    "        wrist = skeleton[:, 0:1, :]\n",
    "        skeleton = skeleton - wrist\n",
    "        dist = np.linalg.norm(skeleton[:, 9, :] - skeleton[:, 0, :], axis=1, keepdims=True) + 1e-6\n",
    "        skeleton = skeleton / dist[:, :, np.newaxis]\n",
    "        return skeleton.reshape(T, -1)\n",
    "\n",
    "class ComputeVelocity: # 속도 계산\n",
    "    def __call__(self, x):\n",
    "        velocity = np.zeros_like(x)\n",
    "        velocity[1:] = x[1:] - x[:-1]\n",
    "        combined = np.concatenate([x, velocity], axis=1)\n",
    "        return combined\n",
    "\n",
    "class ToTensorAndPad: # 제로 패딩\n",
    "    def __init__(self, max_len=40):\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, x):\n",
    "        seq_len = x.shape[0]\n",
    "        input_dim = x.shape[1]\n",
    "        if seq_len < self.max_len:\n",
    "            pad_len = self.max_len - seq_len\n",
    "            padding = np.zeros((pad_len, input_dim), dtype=np.float32)\n",
    "            x = np.vstack([x, padding])\n",
    "        else:\n",
    "            x = x[:self.max_len, :]\n",
    "        x = x.transpose(1, 0)\n",
    "        return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for t in self.transforms:\n",
    "            x = t(x)\n",
    "        return x\n",
    "\n",
    "class HoloTouchCollate:\n",
    "    def __init__(self, is_train=False):\n",
    "        transforms_list = [NormalizeSkeleton(), ComputeVelocity()]\n",
    "        if is_train:\n",
    "            transforms_list.insert(0, RandomHorizontalFlip(p=0.5))\n",
    "        transforms_list.append(ToTensorAndPad(MAX_SEQ_LEN))\n",
    "        self.transform = Compose(transforms_list)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        inputs, targets = [], []\n",
    "        for feature, label in batch:\n",
    "            processed_feature = self.transform(feature)\n",
    "            inputs.append(processed_feature)\n",
    "            targets.append(label)\n",
    "        return torch.stack(inputs), torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "# 유틸리티 정의\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, path=SAVE_MODEL_PATH):\n",
    "        self.patience = patience\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "        elif val_loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        print(f\"Best Model Saved! (Loss: {self.best_loss:.4f})\")\n",
    "\n",
    "def make_weighted_sampler_for_subset(dataset, indices):\n",
    "    subset_labels = dataset.get_labels_by_indices(indices)\n",
    "    class_counts = np.bincount(subset_labels, minlength=NUM_CLASSES)\n",
    "    class_weights = 1. / (class_counts + 1e-6)\n",
    "    sample_weights = [class_weights[l] for l in subset_labels]\n",
    "    return WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "def main():\n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(\"Starting Training with Train/Val Split...\")\n",
    "\n",
    "    full_dataset = JesterRawDataset(TRAIN_CSV)\n",
    "\n",
    "    indices = np.arange(len(full_dataset))\n",
    "    labels = full_dataset.labels\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices,\n",
    "        test_size=VAL_SIZE,\n",
    "        stratify=labels,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Data Split: Train {len(train_idx)} / Val {len(val_idx)}\")\n",
    "\n",
    "    train_subset = Subset(full_dataset, train_idx)\n",
    "    val_subset = Subset(full_dataset, val_idx)\n",
    "\n",
    "    train_sampler = make_weighted_sampler_for_subset(full_dataset, train_idx) # Train용 가중치 샘플러 (클래스 불균형 해소)\n",
    "\n",
    "    # Train은 증강O, Val은 증강X\n",
    "    train_collate = HoloTouchCollate(is_train=True)\n",
    "    val_collate = HoloTouchCollate(is_train=False)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        collate_fn=train_collate,\n",
    "        num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=val_collate,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    model = SE_TCN(\n",
    "        num_inputs=INPUT_CHANNELS,\n",
    "        num_channels=[64, 64, 128, 128],\n",
    "        num_classes=NUM_CLASSES\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE, path=SAVE_MODEL_PATH)\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        #  Train \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds, train_targets_list = [], []\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Ep {epoch+1}/{EPOCHS}\", leave=False)\n",
    "        for inputs, targets in loop:\n",
    "\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)     \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets_list.extend(targets.cpu().numpy())\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = accuracy_score(train_targets_list, train_preds)\n",
    "\n",
    "        #  Val \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds, val_targets_list = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = nn.CrossEntropyLoss()(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = accuracy_score(val_targets_list, val_preds)\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"Ep {epoch+1} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # 스케줄러 & Early Stopping\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss, model)\n",
    " \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Training Finished!\")\n",
    "    print(f\"Best Val Accuracy: {best_acc:.4f}\")\n",
    "    print(f\"Model saved to: {SAVE_MODEL_PATH}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a160529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_5864\\3963470636.py:53: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W1214 11:19:11.687000 5864 site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from best_split_model.pth...\n",
      "PyTorch Model loaded successfully.\n",
      "Exporting to HoloTouch_SE_TCN.onnx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1214 11:19:12.190000 5864 site-packages\\torch\\onnx\\_internal\\exporter\\_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `SE_TCN([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `SE_TCN([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
      "Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 20 of general pattern rewrite rules.\n",
      "Conversion Complete! Saved as 'HoloTouch_SE_TCN.onnx'\n",
      "ONNX Model sanity check passed.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_onnx\n",
    "import torch.onnx\n",
    "from model import SE_TCN\n",
    "# ==========================================\n",
    "# 1. 설정 (학습 때와 동일하게 맞춰야 함)\n",
    "# ==========================================\n",
    "MODEL_PATH = \"best_split_model.pth\"   # 변환할 PyTorch 모델 경로\n",
    "ONNX_PATH = \"HoloTouch_SE_TCN.onnx\"   # 저장할 ONNX 파일 이름\n",
    "\n",
    "# 모델 하이퍼파라미터\n",
    "INPUT_CHANNELS = 126   # (21관절 * 3좌표) + (21관절 * 3속도)\n",
    "NUM_CLASSES = 8        # 라벨 개수\n",
    "MAX_SEQ_LEN = 40       # 시퀀스 길이\n",
    "HIDDEN_CHANNELS = [64, 64, 128, 128] # 모델 구조\n",
    "\n",
    "# ==========================================\n",
    "# 2. 모델 로드 및 준비\n",
    "# ==========================================\n",
    "def convert():\n",
    "    print(f\"Loading model from {MODEL_PATH}...\")\n",
    "    \n",
    "    # 모델 초기화 (CPU 모드로 로드 권장)\n",
    "    device = torch.device('cpu')\n",
    "    model = SE_TCN(\n",
    "        num_inputs=INPUT_CHANNELS, \n",
    "        num_channels=HIDDEN_CHANNELS, \n",
    "        num_classes=NUM_CLASSES\n",
    "    ).to(device)\n",
    "\n",
    "    try:\n",
    "        # 가중치 로드\n",
    "        checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"PyTorch Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\")\n",
    "        return\n",
    "\n",
    "    # [중요] 평가 모드로 전환 (Dropout, BatchNorm 등의 동작 고정)\n",
    "    model.eval()\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. Dummy Input 생성 (모델 구조 파악용)\n",
    "    # ==========================================\n",
    "    # Shape: (Batch_Size, Channels, Seq_Len) -> (1, 126, 40)\n",
    "    dummy_input = torch.randn(1, INPUT_CHANNELS, MAX_SEQ_LEN, requires_grad=True).to(device)\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. ONNX Export 실행\n",
    "    # ==========================================\n",
    "    print(f\"Exporting to {ONNX_PATH}...\")\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model,                      # 실행할 모델\n",
    "        dummy_input,                # 모델 입력을 정의하는 더미 데이터\n",
    "        ONNX_PATH,                  # 저장 경로\n",
    "        export_params=True,         # 가중치 포함 여부\n",
    "        opset_version=12,           # ONNX 버전 (11 or 12 권장)\n",
    "        do_constant_folding=True,   # 상수 폴딩 최적화\n",
    "        input_names=['input'],      # 입력 노드 이름 (나중에 추론할 때 씀)\n",
    "        output_names=['output'],    # 출력 노드 이름\n",
    "        dynamic_axes={              # 가변적인 차원 설정 (배치 사이즈 등)\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"Conversion Complete! Saved as '{ONNX_PATH}'\")\n",
    "    \n",
    "    # (선택) ONNX 파일 검증\n",
    "    try:\n",
    "        import onnx\n",
    "        onnx_model = onnx.load(ONNX_PATH)\n",
    "        onnx.checker.check_model(onnx_model)\n",
    "        print(\"ONNX Model sanity check passed.\")\n",
    "    except ImportError:\n",
    "        print(\"onnx' library not installed. Skipping validation.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ONNX Model check failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2449e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from best_split_model.pth...\n",
      "PyTorch Model loaded successfully.\n",
      "Removing weight_norm for Sentis compatibility...\n",
      "Removed weight_norm from conv1\n",
      "Removed weight_norm from conv2\n",
      "Removed weight_norm from conv1\n",
      "Removed weight_norm from conv2\n",
      "Removed weight_norm from conv1\n",
      "Removed weight_norm from conv2\n",
      "Removed weight_norm from conv1\n",
      "Removed weight_norm from conv2\n",
      "Exporting to HoloTouch_SE_TCN_Fixed.onnx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_39904\\1301154849.py:61: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W1214 16:44:51.693000 39904 site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
      "W1214 16:44:52.474000 39904 site-packages\\torch\\onnx\\_internal\\exporter\\_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `SE_TCN([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `SE_TCN([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
      "Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "  File \"d:\\Program\\anaconda3\\envs\\dl\\lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 20 of general pattern rewrite rules.\n",
      "Conversion Complete! Saved as 'HoloTouch_SE_TCN_Fixed.onnx'\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# [수정됨] ONNX 변환 코드 (weight_norm 제거 포함)\n",
    "# ==========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import remove_weight_norm\n",
    "from model import SE_TCN\n",
    "\n",
    "# 1. 설정\n",
    "MODEL_PATH = \"best_split_model.pth\"   \n",
    "ONNX_PATH = \"HoloTouch_SE_TCN_Fixed.onnx\" # 이름 변경 권장\n",
    "\n",
    "# 모델 하이퍼파라미터 (학습 때와 동일하게)\n",
    "INPUT_CHANNELS = 126\n",
    "NUM_CLASSES = 8\n",
    "HIDDEN_CHANNELS = [64, 64, 128, 128]\n",
    "\n",
    "# 2. weight_norm 제거 함수 (★ 핵심 ★)\n",
    "# TCN 모델은 weight_norm을 쓰는데, 이게 ONNX/Sentis에서 버그를 자주 일으킵니다.\n",
    "# 변환 전에 이를 제거하여 순수 Convolution 가중치로 고정해야 합니다.\n",
    "def remove_norm(module):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, (nn.Conv1d, nn.Linear)):\n",
    "            # weight_norm이 적용된 레이어인지 확인\n",
    "            if hasattr(child, 'weight_g'): \n",
    "                remove_weight_norm(child)\n",
    "                print(f\"Removed weight_norm from {name}\")\n",
    "        else:\n",
    "            remove_norm(child)\n",
    "\n",
    "def convert():\n",
    "    print(f\"Loading model from {MODEL_PATH}...\")\n",
    "    \n",
    "    device = torch.device('cpu') # 변환은 CPU에서 하는 것이 안전함\n",
    "    model = SE_TCN(\n",
    "        num_inputs=INPUT_CHANNELS, \n",
    "        num_channels=HIDDEN_CHANNELS, \n",
    "        num_classes=NUM_CLASSES\n",
    "    ).to(device)\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"PyTorch Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model: {e}\")\n",
    "        return\n",
    "\n",
    "    # [중요 1] 평가 모드\n",
    "    model.eval()\n",
    "\n",
    "    # [중요 2] weight_norm 제거 (Sentis 호환성 확보)\n",
    "    print(\"Removing weight_norm for Sentis compatibility...\")\n",
    "    remove_norm(model)\n",
    "\n",
    "    # 3. Dummy Input (배치 1, 채널 126, 시퀀스 40)\n",
    "    dummy_input = torch.randn(1, INPUT_CHANNELS, 40, requires_grad=False).to(device)\n",
    "\n",
    "    # 4. ONNX Export\n",
    "    print(f\"Exporting to {ONNX_PATH}...\")\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        ONNX_PATH,\n",
    "        export_params=True,\n",
    "        opset_version=12,           # Sentis 권장 버전\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    print(f\"Conversion Complete! Saved as '{ONNX_PATH}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e3d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
